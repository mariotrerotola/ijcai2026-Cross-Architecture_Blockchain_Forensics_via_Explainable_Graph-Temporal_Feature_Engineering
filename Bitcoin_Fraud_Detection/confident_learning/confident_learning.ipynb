{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d92f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Label noise detection with Cleanlab (fraud-only filtering).\n",
    "\n",
    "This notebook finds potentially mislabeled fraud entries in a binary\n",
    "fraud vs. licit dataset using Cleanlab's find_label_issues. It retrains\n",
    "a RandomForest on the cleaned subset (only fraud labels affected) to\n",
    "compare F1 performance.\n",
    "\n",
    "Main change vs. the original:\n",
    "- Outliers are removed only if the sample is labeled fraud (1).\n",
    "- Licit rows remain untouched even if flagged by Cleanlab.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q cleanlab tqdm matplotlib scikit-learn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1. Imports and configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cleanlab.filter import find_label_issues\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1. Imports and configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cleanlab.filter import find_label_issues\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configuration ---------------------------------------------------------------\n",
    "BASE_DIR = Path(\"../data/processed_data\")  # Adjust as needed\n",
    "USE_CASE = \"case_3.csv\"\n",
    "DATA_PATH = BASE_DIR / USE_CASE\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Logging ---------------------------------------------------------------------\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "log = logging.getLogger(\"cleanlab-pipeline\")\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacf7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 2. Load dataset and map labels (fraud=1, licit=0)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if \"class\" not in df.columns:\n",
    "    raise KeyError(\"Column 'class' not found in dataset\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"class\"])  # Expecting labels {\"fraud\",\"licit\"}\n",
    "if set(le.classes_) != {\"fraud\", \"licit\"}:\n",
    "    raise ValueError(\"Expected labels 'fraud' and 'licit' only\")\n",
    "\n",
    "fraud_is_index1 = list(le.classes_).index(\"fraud\") == 1\n",
    "labels = le.transform(df[\"class\"])  # 0/1 but check order\n",
    "if not fraud_is_index1:\n",
    "    labels = 1 - labels  # Flip so fraud=1, licit=0\n",
    "log.info(\"Label encoding: %s -> [0,1] if fraud at index1? %s\", list(le.classes_), fraud_is_index1)\n",
    "log.info(\"Class counts: %s\", dict(pd.Series(labels).value_counts()))\n",
    "\n",
    "df[\"y\"] = labels\n",
    "X = df.drop(columns=[\"class\", \"y\"]).values\n",
    "y = df[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3. Train/test split & baseline RandomForest\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "baseline_f1 = f1_score(y_test, y_pred)\n",
    "log.info(\"Baseline F1 on holdout set: %.3f\", baseline_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e02f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 4. Cleanlab: detect potential label issues via cross-validated predict_proba\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "log.info(\"Running %s-fold CV predict_proba on full dataset...\", CV_FOLDS)\n",
    "probs_full = cross_val_predict(\n",
    "    clf, X, y, cv=CV_FOLDS, method=\"predict_proba\", n_jobs=-1\n",
    ")\n",
    "\n",
    "noise_indices_all = find_label_issues(\n",
    "    labels=y, pred_probs=probs_full, return_indices_ranked_by=\"self_confidence\"\n",
    ")\n",
    "\n",
    "# Keep only indices where the current label is fraud (1) ----------------------\n",
    "fraud_noise_indices = [idx for idx in noise_indices_all if y[idx] == 1]\n",
    "noise_rate_fraud = len(fraud_noise_indices) / (y.sum() if y.sum() else 1)\n",
    "log.info(\n",
    "    \"Detected %s suspect FRAUD labels (%.2f%% of fraud data)\",\n",
    "    len(fraud_noise_indices),\n",
    "    100 * noise_rate_fraud,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 5. Remove suspect FRAUD rows and retrain RandomForest on cleaned subset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "mask_clean = np.ones(len(y), dtype=bool)\n",
    "mask_clean[fraud_noise_indices] = False\n",
    "\n",
    "X_clean = X[mask_clean]\n",
    "y_clean = y[mask_clean]\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=TEST_SIZE, stratify=y_clean, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "clf_clean = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "clf_clean.fit(Xc_train, yc_train)\n",
    "\n",
    "yc_pred = clf_clean.predict(Xc_test)\n",
    "clean_f1 = f1_score(yc_test, yc_pred)\n",
    "log.info(\n",
    "    \"F1 after removing suspect FRAUD labels: %.3f (delta = %.3f)\",\n",
    "    clean_f1,\n",
    "    clean_f1 - baseline_f1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f80acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 6. Display top 10 suspect FRAUD indices and plot noise vs clean counts\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Top 10 FRAUD indices flagged as potential label errors:\")\n",
    "print(fraud_noise_indices[:10])\n",
    "\n",
    "# Plot count of suspect vs clean FRAUD labels\n",
    "num_fraud = y.sum()\n",
    "num_suspect_fraud = len(fraud_noise_indices)\n",
    "num_clean_fraud = num_fraud - num_suspect_fraud\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar([\"Fraud Clean\", \"Fraud Suspect\"], [num_clean_fraud, num_suspect_fraud])\n",
    "plt.title(\"Label Noise within FRAUD samples\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dexire-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
